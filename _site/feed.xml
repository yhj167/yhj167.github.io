<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yinhj Blog</title>
    <description>关于后端与架构、分布式与大数据 | 殷华杰，Web &amp; 后端开发，分布式架构设计 | 这里是 @Yinhj殷华杰 的个人博客，与你一起发现更大的世界。</description>
    <link>http://yhj167.github.io/</link>
    <atom:link href="http://yhj167.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sun, 11 Dec 2016 00:13:18 +0800</pubDate>
    <lastBuildDate>Sun, 11 Dec 2016 00:13:18 +0800</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>[机器学习]TensorFlow安装与入门</title>
        <description>&lt;p&gt;​    virtualenv 可以用来建立一个专属于项目的python环境，保持一个干净的环境。只需要通过命令创建一个虚拟环境，不用的时候通过命令退出，删除。&lt;strong&gt;实践证明用虚拟环境能避免很多糟心的事。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;下面介绍一下安装方法：&lt;/p&gt;

&lt;p&gt;安装 virtualenv;&lt;/p&gt;

&lt;p&gt;安装 virtualenvwrapper;&lt;/p&gt;

&lt;p&gt;安装 Numpy，Scipy，Matplotlib 等Python科学计算的库;&lt;/p&gt;

&lt;h3 id=&quot;virtualenv&quot;&gt;1.安装 virtualenv&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;$ sudo pip install virtualenv&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;然后建立一个测试目录：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$ mkdir testvirtual&lt;/p&gt;

  &lt;p&gt;$ cd testvirtual&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;就可以成功创建一个虚拟环境 env1：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$ virtualenv env1&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;进入env1:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;source env1/bin/activate&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;退出:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;deactivate&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;virtualenvwrapper&quot;&gt;2.安装 virtualenvwrapper&lt;/h3&gt;

&lt;p&gt;Virtaulenvwrapper是virtualenv的扩展包，可以更方便地新增，删除，复制，切换虚拟环境。&lt;/p&gt;

&lt;p&gt;运行下面命令就安装成功了，默认安装在 /usr/local/bin下面：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$ sudo easy_install virtualenvwrapper&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;接下来创建一个文件夹，用来存放所有的虚拟环境：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$ mkdir ~/workspaces&lt;/p&gt;

  &lt;p&gt;$ cd ~/workspaces&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;但是在使用virtualenvwrapper之前，要运行virtualenvwrapper.sh文件，需要设置环境变量，vim  ~/.bashrc打开配置文件，把下面两行代码加上，&lt;strong&gt;但是mac比较特殊直接写不管用&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;export WORKON_HOME=~/workspaces&lt;/p&gt;

  &lt;p&gt;source /usr/local/bin/virtualenvwrapper.sh&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;因为&lt;strong&gt;unix下当shell是login shell，.bash_profile才加载，而.bashrc相反&lt;/strong&gt;。
Linux下，打开终端terminal是non-login shell。
OSX下，运行Terminal.app是一个login shell，所以.bash_profile会加载，而bashrc不会加载。&lt;/p&gt;

&lt;p&gt;直接在命令行写也可以，但是每次启动shell都要手动输入很麻烦，下面是解决方法是 vim ~/.bash_profile打开配置文件把下面代码加上：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;if [ “${BASH-no}” != “no” ]; then&lt;/p&gt;

  &lt;p&gt;​	[ -r ~/.bashrc ] &amp;amp;&amp;amp; . ~/.bashrc&lt;/p&gt;

  &lt;p&gt;fi&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;接下来，创建一个或者多个虚拟环境 env1，env2：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$ mkvirtualenv env1&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;成功后，当前路径前面就会有 (env1)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$ mkvirtualenv env2&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;section&quot;&gt;下面是一些基本操作命令&lt;/h4&gt;

&lt;p&gt;列出虚拟环境：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$ lsvirtualenv -b&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;env1&lt;/p&gt;

  &lt;p&gt;env2&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;切换虚拟环境：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$ workon env1&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;查看环境里安装了哪些包：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$ lssitepackages&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;进入当前环境：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$ cdvirtualenv&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;进入当前环境的site-packages：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$ cdsitepackages&lt;/p&gt;

  &lt;p&gt;$ cdsitepackages pip&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;复制虚拟环境：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$ cpvirtualenv env1 env3&lt;/p&gt;

  &lt;p&gt;Copying env1 as env3…&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;退出虚拟环境：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$ deactivate&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;删除虚拟环境：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$ rmvirtualenv env2&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Removing env2…&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;numpyscipymatplotlib-&quot;&gt;3.安装 Numpy，Scipy，Matplotlib 等&lt;/h3&gt;

&lt;p&gt;接下来安装Python的各种包，就比较顺畅了，比如安在env1上：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ workon env1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;安装numpy&lt;/strong&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install numpy&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;我没安装成功，然后下载后本地安装的：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install /Users/Angela/Downloads/numpy-1.11.2-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;最好都本地安装，大多直接安装不成功。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;安装scipy&lt;/strong&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;$ pip install scipy&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;安装matplotlib&lt;/strong&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;$ pip install matplotlib&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;安装ipython&lt;/strong&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;$ pip install ipython[all]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;安装pandas&lt;/strong&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;$ pip install pandas&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;安装Statsmodel&lt;/strong&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;$ pip install statsmodel&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;安装scikit-learn&lt;/strong&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;$ pip install scikit-learn&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;按照顺序全部安装成功，后续就可以在虚拟环境上做分析了。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;以后每次进入虚拟环境就执行如下代码即可：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ workon env1
$ cdvirtualenv
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;退出虚拟环境就用&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ deactivate
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;virtualenvpip&quot;&gt;4.virtualenv自带pip，如果不用虚拟环境也行。&lt;/h3&gt;
&lt;p&gt;安装pip方法如下：
pip是常用的Python包管理工具，类似于Java的maven。用python的同学，都离不开pip。 
在新mac中想用home-brew安装pip时，遇到了一些小问题：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
bogon:~ wanglei$ brew install pip
Error: No available formula with the name &quot;pip&quot;
Homebrew provides pip via: `brew install python`. However you will then
have two Pythons installed on your Mac, so alternatively you can install
pip via the instructions at:

  https://pip.readthedocs.org/en/stable/installing/#install-pip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由此可见，在home-brew中，pip的安装是跟python一起的。&lt;/p&gt;

&lt;p&gt;换种方式：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
bogon:~ wanglei$ sudo easy_install pip
Password:
Searching for pip
Reading https://pypi.python.org/simple/pip/
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;稍等片刻，pip就安装完毕&lt;/p&gt;

&lt;h3 id=&quot;tensorflow&quot;&gt;5.安装TensorFlow&lt;/h3&gt;

&lt;p&gt;下载tensorflow（可以百度网盘直接下载，避免FQ）。 网盘地址：&lt;a href=&quot;https://pan.baidu.com/s/1dE2i9tn&quot;&gt;tensorflow下载&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;一些依赖包如果安装不顺畅，可以去pypi.python.org直接下载，比如numpy我没安装上，下载包后本地安装上了。&lt;/p&gt;

&lt;p&gt;直接安装依赖包会遇到很多坑，比如和现有版本冲突等安装失败。可以安装virtualenv来隔离环境，会自动安装six-1.10等很多依赖包，之后就可以安装Numpy、Scipy、Matplotlib 等库。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;最后，装完后安装tensorflow&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install /Users/Angela/Downloads/TensorFlow/mac/tensorflow-0.5.0-py2-none-any.whl
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我下载的TensorFlow文件放在/Users/Angela/Downloads/目录’下了。&lt;/p&gt;

</description>
        <pubDate>Tue, 06 Dec 2016 04:00:00 +0800</pubDate>
        <link>http://yhj167.github.io/2016/12/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-TensorFlow%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/</link>
        <guid isPermaLink="true">http://yhj167.github.io/2016/12/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-TensorFlow%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/</guid>
        
        <category>TensorFlow</category>
        
        <category>机器学习</category>
        
        
      </item>
    
      <item>
        <title>[机器学习]开源的深度学习框架</title>
        <description>&lt;p&gt;关于视频分析或者图像处理过程如下：&lt;/p&gt;

&lt;p&gt;1.首先要提取视频中的运动物体，常用算法有：帧差法，GMM，vibe等；&lt;/p&gt;

&lt;p&gt;2.提取前景（运动物体）后对其进行跟踪，主要算法有：camshift，粒子滤波，TLD，压缩感知等；&lt;/p&gt;

&lt;p&gt;3.对监控视频的去模糊，去雾，夜视增强等，可基于opencv来实现。&lt;/p&gt;

&lt;p&gt;4.最后通过机器学习对视频进行分析。&lt;/p&gt;

&lt;p&gt;下面着重介绍机器学习的分支：深度学习，也就是深度神经网络，是近来比较火热的领域。很多机器学习实现的功能很难用到商用中，比如人脸识别，传统的机器学习方法受光照，角度干扰太大，很难达到较好的识别率，深度学习在图像中的应用已经有很多了。这里介绍几个开源框架：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s/a1gpiBxOo8VpyUMBs4yutg&quot;&gt;AI从业者该如何选择深度学习框架&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.jianshu.com/p/fe4dc3b72064&quot;&gt;深度学习网址&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;其他资料：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;caffe&quot;&gt;1.caffe：&lt;/h3&gt;
&lt;p&gt;c++，伯克利大学开发，facebook。
&lt;a href=&quot;http://www.zhihu.com/question/47467054/answer/106237592&quot;&gt;caffe开发过程中使用了哪些工具&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Caffe是非常高效的针对画面的深层学习框架。Caffe2是我们的第一个产业级深度学习平台，它可以在服务器CPU、GPU、iOS和安卓四种平台上运行，使用同一种代码。&lt;/p&gt;

&lt;h3 id=&quot;tensorflow&quot;&gt;2.TensorFlow：&lt;/h3&gt;
&lt;p&gt;支持公司：google。&lt;/p&gt;

&lt;p&gt;基于图计算的框架，有一个限制，就是需要用户把所有的计算全部都表示成一张图来高效运行。&lt;/p&gt;

&lt;p&gt;基于图计算的框架也提供了比如自动多卡并行调度，内存优化等便利条件。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Theano的一个优势在于代码是在计算时生成并编译的，所以理论上可以达到更高的速度（不需要运行时的polymorphism，而且如果写得好的话可以fuse kernel），但是因为是学术实现，没有花大精力在优化上面，所以实际速度并不占优势。另外现在大家都高度依赖于第三方库比如说cudnn，所以比较速度已经是上个时代的事情了，不必太在意。&lt;/p&gt;

  &lt;p&gt;另外吐槽一下，TensorFlow的分布式计算不是最快的，单机使用CPU作reduction，多机用基于socket的RPC而不是更快的RDMA，主要的原因是TF现有框架的抽象对于跨设备的通讯不是很友好（最近开始有一些重新设计的倾向，待考）。&lt;/p&gt;

  &lt;p&gt;在分布式上百度美研的解决方案要好得多，没有开源。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;mxnet&quot;&gt;3.mxnet：&lt;/h3&gt;
&lt;p&gt;开源框架。
支持公司：华为、阿里部分团队。
&lt;a href=&quot;http://www.zhihu.com/question/46587833/answer/102006682&quot;&gt;DL框架的未来发展TensorFlow/MXNet/Torch, 选哪个&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;允许用户自由把图计算和过程计算混合起来, 并且可以对多步执行进行自动多卡调度, 使得程序在需要优化的部分可以非常优化,而必要的时候可以通过过程计算来实现一些更加灵活的操作, 并且所有的操作都可以自动并行（TF只能并行一个图的执行，但是不能并行像torch这样的多步执行的操作）。&lt;/p&gt;

&lt;p&gt;MXNet的operator不仅仅局限于MShadow。MShadow只是提供了一个方便的模板，完全可以使用C, C++, CUDA等去实现。同时支持直接采用numpy来写各种operator。另外，目前的mxnet已经做到完全和Torch兼容，以调用所有Torch的Module和Operator （ mxnet/example/torch at master · dmlc/mxnet · GitHub ），所以Torch能做的MXNet就可以做。&lt;/p&gt;

&lt;h3 id=&quot;torch&quot;&gt;4.Torch：&lt;/h3&gt;
&lt;p&gt;torch采取了支持用户把计算拆分成多步来做，用户可以直接利用lua来选择下一步执行什么。用户可以比较简单地对计算进行模块分割，并且根据比如输入长度的不同来直接动态改变需要运行哪一个步骤。&lt;/p&gt;

&lt;p&gt;Torch为代表的过程式计算更加灵活。&lt;/p&gt;

&lt;p&gt;TF由G的优秀工程师设计，更加注重性能和优化。Torch本身是researcher设计的，更加注重灵活性。&lt;/p&gt;

&lt;h3 id=&quot;theano&quot;&gt;5.Theano：&lt;/h3&gt;
&lt;p&gt;TensorFlow和Theano，都是基于Python的符号运算库，TensorFlow显然支持更好，Google也比高校有更多的人力投入。Theano的主要开发者现在都在Google，可以想见将来的工程资源上也会更偏向于TF一些。&lt;/p&gt;
</description>
        <pubDate>Mon, 21 Nov 2016 04:00:00 +0800</pubDate>
        <link>http://yhj167.github.io/2016/11/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%BC%80%E6%BA%90%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/</link>
        <guid isPermaLink="true">http://yhj167.github.io/2016/11/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%BC%80%E6%BA%90%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/</guid>
        
        <category>机器学习</category>
        
        
      </item>
    
      <item>
        <title>[大数据与分布式系统]大数据架构之数据处理</title>
        <description>&lt;h1 id=&quot;section&quot;&gt;离线批量处理&lt;/h1&gt;
&lt;p&gt;海量处理计算框架：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;MapReduce；
管理框架YARN改进了MapReduce的缺点；
计算框架Spark更迅速；
在此基础上，还提出了hive,pig,impala,spark sql等工具。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;mapreduce&quot;&gt;MapReduce：&lt;/h3&gt;
&lt;p&gt;1.分割Data splitting:  数据分片发送到Mapper。
2.映射Mapping: key-value映射。
(合并combining ，在每个mapper节点进行本地归约)
3.洗牌Shuffing:  将key-value的配对发给reducer归约。(可能还包括分配partitioning，例如专门的地点reducer)
4.归约reducing：分析配对，键内容相同，则将值合并。
&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/2886390-263caf0a7dc96a57.jpg&quot; alt=&quot;图片发自简书App&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/2886390-719c7d94608074e7.jpg&quot; alt=&quot;图片发自简书App&quot; /&gt;&lt;/p&gt;

&lt;p&gt;1.工作跟踪节点：决定处理哪些文件、为不同任务分配节点，监控所有任务运行。
2.任务跟踪节点：从节点上运行分配的单项任务。&lt;/p&gt;

&lt;p&gt;缺点：
1.工作节点完成太多功能、资源消耗，单点故障隐患。
2.任务节点用任务数量衡量负载过于简单，map和reduce任务严格划分，可能导致系统资源未充分利用。&lt;/p&gt;

&lt;h3 id=&quot;yarn&quot;&gt;YARN:&lt;/h3&gt;
&lt;p&gt;为上层应用提供统一hadoop资源管理和调度。
将主节点分成两个独立服务程序：全局资源管理和针对每个应用的主节点。让子任务的监测分布式处理。在YARN基础上，还可以运行spark和storm这样的流式计算和实时性作业。&lt;/p&gt;

&lt;h3 id=&quot;spark&quot;&gt;Spark：&lt;/h3&gt;
&lt;p&gt;基于内存计算
弹性分布式数据集（RDD），容错机制
适用机器学习等需要多次迭代的算法
scala语言
兼容HDFS和HBase等分布式存储，可以运行在YARN中。&lt;/p&gt;

&lt;h4 id=&quot;spark-1&quot;&gt;运用spark的公司&lt;/h4&gt;
&lt;p&gt;Hortonworks, IBM, Cloudera, MapR, Pivotal。&lt;/p&gt;

&lt;h4 id=&quot;sparksql&quot;&gt;sparksql&lt;/h4&gt;
&lt;p&gt;基于catalyst的交互式sql
支持hive的多种数据格式&lt;/p&gt;
&lt;h4 id=&quot;spark-streaming&quot;&gt;spark streaming&lt;/h4&gt;
&lt;p&gt;针对实时数据流处理，可对数据进行map, reduce, join等高级操作，将结果输出到文件系统或数据库。&lt;/p&gt;
&lt;h4 id=&quot;spark-graphx&quot;&gt;spark graphX&lt;/h4&gt;
&lt;p&gt;提供用于图计算的api，定义了table和graph两种视图，有自己独自的操作符。&lt;/p&gt;
&lt;h4 id=&quot;mlbase&quot;&gt;MLBase&lt;/h4&gt;
&lt;p&gt;提供简单声明方法指定机器学习任务，动态选择较优的学习算法。&lt;/p&gt;
&lt;h4 id=&quot;spark-r&quot;&gt;spark R&lt;/h4&gt;
&lt;p&gt;开源数据分析软件，通过RDD提供的api，使用R在集群中提交并运行任务。&lt;/p&gt;

&lt;h3 id=&quot;hive&quot;&gt;Hive：&lt;/h3&gt;
&lt;p&gt;hadoop基础上的数据库工具，存储、查询、分析存储在HDFS中的大数据。
1.采用HiveQL来实现数据的提取、转化和加载，将sql转化为mapreduce任务在后台运行。
2.也可自定义开发mapper和reducer来处理內建模块无法完成的复杂工作。&lt;/p&gt;

&lt;p&gt;架构包括用户端、解释器、元数据存储和分析数据存储。
1.用户端：主要包含命令行（CLI）、客户端（Client）和Web图形化界面（WebGUI）。最常用的是CLI，它启动的时候会同时启动一个Hive守护进程服务，使用者可以交互式地输入命令并得到相应的结果输出。Client是Hive的客户端，用户通过它连接到Hive的服务器。Client模式启动的时候，需要启动Hive服务器所在的节点，并进行相应的配置。WebGUI工具允许用户通过浏览器访问Hive，使用前要启动HWI组件（Hive Web Interface）。&lt;/p&gt;

&lt;p&gt;·解释器：主要包含执行编译器、优化器和执行器，它们完成HiveQL查询语句的词法分析、语法分析、编译、优化及计划的生成。生成的查询计划也会存储在HDFS中，并在随后通过MapReduce框架调用执行。这也体现了Hive的核心思想之一，就是尽量简化MapReduce开发的工作量，使得某些操作和查询的复杂逻辑对使用者完全透明。&lt;/p&gt;

&lt;p&gt;·元数据存储：Hive中的元数据包括表的名字、表的列、表分区、表数据所在的目录、是否为外部表，等等。尽管Hive采用NoSQL的方式进行工作，但它仍然使用关系型数据库存储元数据，这点主要是考虑到元数据的规模较小，而对读写同步的要求很高。此外，将元数据的存储从Hive的数据服务中解耦出来，可以大大减少执行语义检查的时间，也能提高整个系统运行的健壮性。常用的关系型数据库配置是MySQL或Derby嵌入式数据库。&lt;/p&gt;

&lt;p&gt;·分析数据存储：Hive用于分析的海量数据都存储在HDFS之中，支持不同的存储类型包括纯文本文件、HBase等文件。一旦解释器接受了HiveQL，那么Hive将直接读取HDFS的数据，并将查询逻辑转化成MapReduce计算来完成。&lt;/p&gt;

&lt;p&gt;Hive的数据模型包括几个主要概念：数据库（Database）、表（Table）、分区（Partition）和桶（Bucket）。&lt;/p&gt;

&lt;p&gt;·数据库：作用是将用户的应用隔离到不同的数据模式中，Hive 0.6.0之后的版本都支持数据库，相当于关系型数据库里的命名空间（Namespace）。&lt;/p&gt;

&lt;p&gt;·表：Hive的表和数据库中的表在概念上非常接近，在逻辑上，其由描述表格形式的元数据和存储于其中的具体数据共同组成，可以分为托管表和外部表。对托管表执行DROP命令的时候，会同时删除元数据和其中存储的数据，而对外部表执行该命令的时候，则只能删除元数据。&lt;/p&gt;

&lt;p&gt;·分区：Hive中的分区方式和数据库中的差异很大，它的概念是根据分区列对表中的数据进行大致地划分，表的分区在Hive存储上就体现为主目录下的多个子目录，而子目录的名称就是分区列的名称。使用分区的好处在于，查询某个具体分区列里的数据时不用进行全表扫描，可以大大加快范围内的查询。&lt;/p&gt;

&lt;p&gt;·桶：表和分区都是在目录级别上进行数据的拆分，而桶则是对数据源数据文件本身进行数据拆分。
&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/2886390-611670baccbaa1e1.jpg&quot; alt=&quot;图片发自简书App&quot; /&gt;&lt;/p&gt;

&lt;p&gt;·查询语言：由于底层依赖于Hadoop的平台，因此HiveQL不支持更新操作，也不支持索引和事务，子查询和连接（Join）操作也很有限。另外，HiveQL还有些特点是关系型SQL所无法企及的，比如和MapReduce计算过程的集成和多表查询。&lt;/p&gt;

&lt;p&gt;·存储方式和计算模型：Hive和关系型数据库相比，存储和计算的方式也不同。Hive使用的是Hadoop的HDFS分布式文件系统和mapreduce。&lt;/p&gt;

&lt;p&gt;·实时性：由于架构在Hadoop之上，Hive也继承了其批处理的方式，因此在作业提交和调度的时候需要大量的开销，并且不能在大规模数据集上实现低延迟地快速查询，自然相较于关系型数据库而言其实时性就较差了。&lt;/p&gt;

&lt;p&gt;·扩展性、并行性和容错性：好。&lt;/p&gt;

&lt;h3 id=&quot;pig-impala-spark-sql&quot;&gt;Pig, Impala, SPARK SQL：&lt;/h3&gt;
&lt;p&gt;有些开发者，虽然对SQL不甚理解，但是擅于MapReduce的编程。&lt;a href=&quot;http://pig.apache.org&quot;&gt;Pig&lt;/a&gt;就是在这样的背景下应运而生的，Pig为大型数据集的处理提供了更高层次的抽象，以及更丰富的数据结构。&lt;/p&gt;

&lt;p&gt;另一个执行于现有Hadoop基础设施上的互动SQL查询引擎是Impala，它是Cloudera公司主导开发的查询系统，目前的最新版本是2.1。类似Apache Hive，Impala也能通过类SQL的语言查询存储在HDFS和HBase中的PB级大数据。不过，Impala考虑了实时性更强的需求，为了实现这一点，Impala参考了Google的交互式数据分析系统Dremel。Impala使用Parquet实现了列存储，并借鉴了MPP并行数据库的思想。同时，它采用HiveQL和JDBC等接口，进行全局统一的元数据存储和读取。对于用户查询则是直接进行分布式处理，在HDFS或HBase上本地读写，因此具有良好的扩展性和容错性。此外，由于放弃了MapReduce的运行框架，它也没有MapReduce作业启动、洗牌、排序等开销，无须将中间结果写入磁盘，节省了大量的I/O开销，也降低了网络传输的数据量。当然，Impala并不是用来取代现有的MapReduce框架的，而是作为MapReduce的一个强力补充。一般而言，Impala更适合处理输出数据较小的查询请求，而对于大数据量的批处理任务，MapReduce依然是更好的选择。&lt;/p&gt;

&lt;p&gt;Spark SQL，它是基于Catalyst引擎的交互式SQL技术，主要优化了以下几个方面。&lt;/p&gt;

&lt;p&gt;·执行策略：Spark SQL在Hive兼容层面仅仅依赖于HiveQL解析器和元数据存储。从HiveQL被解析成抽象语法树之后，就全部由Spark SQL来接管了。执行计划的生成和优化均由Catalyst引擎来负责，借助Scala的模式匹配等函数式语言的特性，其策略比Hive更为简洁。&lt;/p&gt;

&lt;p&gt;·进入门槛：Spark SQL能够对原生RDD对象进行关系查询，因此大大降低了用户门槛。虽然在很多方面Spark的性能优于Hadoop的MapReduce，但其运行模型也比MapReduce精细不少，这就使得Spark应用的性能调优比较复杂。单纯使用Spark的接口开发是需要花些学习成本的。这时就体现出了Spark SQL的优势——相比底层接口，SQL语言的接受程度更高，这和Hive相对于MapReduce的情况类似。更何况Catalyst引擎还提供了一系列常见的优化策略来协助用户实现目标。&lt;/p&gt;

&lt;p&gt;·对Hive的依赖：相对于Shark，Spark SQL进一步削减了对Hive的依赖，不再需要自行维护打了补丁的Hive分支。因此，Shark后续将全面采用Spark SQL作为引擎，而不仅仅是查询优化方面。&lt;/p&gt;

&lt;h1 id=&quot;section-1&quot;&gt;提升及时性：消息机制&lt;/h1&gt;
&lt;p&gt;两种模型：点对点、发布订阅模型。
无论是哪种消息传送模式，都可以提升数据更新的及时性，并对复杂的系统架构进行解耦。举个例子，对于重点观察的用户行为，如果还是通过Flume这样的批量采集方式，可能无法达到业务方提出的实时监控和分析的需求。而消息的机制可以很好地解决这个问题。另外，由于消息机制的实时性更强，通常它还会和稍后介绍的Spark Streaming、Storm这样的流式计算结合起来使用。
ApacheMQ：
ActiveMQ的主要目标是在尽可能多的跨平台和跨语言上提供一个统一的、标准的消息驱动的应用集成。
ActiveMQ同样以异步的形式提供松耦合的应用架构。
JMS规范保证了同步和异步消息传递、一次和仅一次的传递、对于订阅者的消息持久化，等等。基于JMS规范使得ActiveMQ和其他消息提供者拥有类似的基本特性。
支持多种连接协议：ActiveMQ提供了各种连接选择，包括HTTP、HTTPS、SSL、TCP、UDP、XMPP、IP多点传送等。
ActiveMQ既支持标准的JDBC方案，也可以通过KahaDB提供超快的持久方案。
多个ActiveMQ代理可以通过代理网络（Network of Brokers）进行联合的工作。
ActiveMQ提供了各种简便而又强大的管理方式，除了Java语言中最基本的JConsole，还有ActiveMQ Web Console、消息报告和各种系统日志等。&lt;/p&gt;

&lt;p&gt;Kafka：
·高性能存储：通过特别设计的磁盘数据结构，保证时间复杂度为O（1）的消息持久化，这样数以TB的消息存储也能够保持良好的稳定性能。此外，被保存的消息可以多次被消费，用于商务智能ETL和其他一些实时应用程序。
·天生分布式：Kafka被设计为一个分布式系统，它利用ZooKeeper来管理多个代理（Broker），支持负载均衡和副本机制，易于横向地扩展。ZooKeeper旨在构建可靠的、分布式的数据结构，这里用于管理和协调Kafka代理。当系统中新增了代理，或者某个代理故障失效时，ZooKeeper服务会通知生产者和消费者，让它们据此开始与其他代理协调工作。
·高吞吐量：由于存储性能的大幅提升，以及良好的横向扩展性，因此即使是非常普通的硬件Kafka也可以支持每秒数十万的消息流，同时为发布和订阅提供惊人的吞吐量。
·无状态代理：与其他消息系统不同，Kafka代理是无状态的。代理不会记录消息被消费的状态，而是需要消费者各自维护。
·主题（Topic）和分区（Partition）：支持通过Kafka服务器和消费机集群来分区消息。一个主题可以认为是一类消息，而每个主题可以分成多个分区。通过分区，可以将数据分散到多个服务器上，避免达到单机瓶颈。更多的分区意味着可以容纳更多的消费者，有效提升并发消费的能力。基于副本方案，还能够对多个分区进行备份和调度。
·消费者分组（Consumer Group）：Kafka中每个消费者均属于一个分组，每个分组中可以有多个消费者。主题中的某条消息可以被多个分组获得，不过同一分组中，只有一个消费者会获得该消息。&lt;/p&gt;

&lt;p&gt;考虑到重复接收数据总比丢失数据要好，通常情况下Kafka的“至少一次”机制是使用者的首选。整体而言，对于一些常规的消息系统，Kafka是个理想的选择。内在的分布式设计、分区和副本，使得其具有良好的扩展性、容错性和性能优势。不过，目前Kafka并没有提供JMS中的事务性消息传输，无法严格地保证消息一定被处理，或者只被处理一次，适合那些对一致性要求不高的应用场景。
&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/2886390-83d077b95bd3f60d.jpg&quot; alt=&quot;kafka架构&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;section-2&quot;&gt;在线实时处理：&lt;/h1&gt;
&lt;p&gt;Storm：
Storm为分布式实时计算提供了一组通用原语，这是管理队列及工作者集群的另一种方式。在计算时就将结果以流的形式输出给用户，从而进一步提升实时性。&lt;/p&gt;

&lt;p&gt;·元组：这是Storm中使用的一种数据结构，包含了若干个键–值对（Key-Value Pair）的列表，这里的键–值对的定义和第3章散列表中所提到的类似。元组以一种分布式的方式并行地在Storm集群上进行创建和处理。
·数据流：数据流是Storm中非常重要的一个抽象概念，是一个没有边界的元组序列，由Spout和Bolt进行发送和转发。对数据流的定义主要就是对其中的元组进行定义，此外还需要为其分配唯一的标识ID。
·Spout：英文单词Spout翻译过来就是水龙头的意思，顾名思义它是提供数据源的，是一个计算任务中数据的生产者。Spout可以从数据库或文件系统等加载数据，然后作为入口，向由若干节点组成的拓扑结构中发送数据流。每个Spout都可以发送多个数据流，同时也可以按照送达的可靠性划分等级。
·Bolt：可以将其理解为运算或函数，用于将一个或多个数据流作为输入，实施加工处理后，再进行新数据流的输出。Bolt可以接受Spout或其他Bolt发送的数据，并据此建立复杂的流转网络，形成最终的拓扑结构，完成对整条流水线数据的操作。Storm计算中的逻辑几乎都在Bolt中完成，例如过滤、分类、聚集、计算、查询数据库等。
·流量分组：它决定了Spout和Bolt节点之间相互连接的方式，主要分为以下几种类型。
·洗牌分组（Shuffle Grouping）：随机地将元组分发到各个Bolt上，理论上这样做的结果是每个Bolt都会接收到同样数量的元组。
·按字段值分组（Fields Grouping）：按照指定的元组字段来进行分组。例如，按照“水质”来划分，那么具有同等质量的水源会被分到一组，发送到同一个或同一组Bolt上。这个逻辑和Hadoop中的MapReduce框架非常相似，这样一来，数据流上游的Spout或Bolt节点就和Mapper比较接近，而下游的Bolt节点则和Reducer比较接近。
·广播（All）：所有的元组都会发送到所有的Bolt上。
·全局（Global）：所有的元组都发送到全局指定的某个Bolt上。
·不做指定（None）：目前等同于洗牌分组，将来可能会进行新的定义扩充。
·指定分组（Direct）：明确指定元组发送到哪个确切的Bolt上。
·拓扑结构：它是由流量分组连接起来的Spout和Bolt节点网络。在Storm中，一个实时计算应用程序的逻辑被封装在一个拓扑对象中，也可以称为计算拓扑。如果和Hadoop的生态系统对比，拓扑结构类似于MapReduce的任务，但是它们之间的关键区别在于，一个MapReduce任务最终总是会结束的，然而一个Storm的拓扑结构会一直运行，直到使用者主动关闭或出现异常。
&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/2886390-28690344b97f50b5.jpg&quot; alt=&quot;图片发自简书App&quot; /&gt;&lt;/p&gt;

&lt;p&gt;SparkStreaming：
Spark Streaming会把每块数据作为一个RDD，每个块都会生成一个Spark的任务来进行处理，最终结果也会返回多块。由于使用了这种设计模式，因此Spark Streaming可以同时兼容批量和实时数据的处理逻辑，以便于历史数据的融合。
Spark Streaming是处理某个时间段窗口内的事件，而Storm处理的是每次传入的单个事件，理论上Spark Streaming的延时性要比Storm略高。不过RDD的机制赋予了Spark Streaming更高的灵活性和容错性。在Storm中，每个单独的记录通过系统时必须被跟踪，这样Storm才能够保证每个记录至少被处理一次。但是在从错误中恢复过来的时候Storm允许出现重复记录，这就意味着某些状态可能被错误地更新多次。而Spark Streaming只需要在批量级别进行跟踪处理，即便一个节点发生故障，也可以有效地保证每个时间窗内的小量数据被完整地处理一次。&lt;/p&gt;
</description>
        <pubDate>Fri, 11 Nov 2016 04:00:00 +0800</pubDate>
        <link>http://yhj167.github.io/2016/11/11/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</link>
        <guid isPermaLink="true">http://yhj167.github.io/2016/11/11/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</guid>
        
        <category>大数据与分布式系统</category>
        
        
      </item>
    
      <item>
        <title>[大数据与分布式系统]大数据架构之数据存储</title>
        <description>&lt;h1 id=&quot;section&quot;&gt;持久化存储&lt;/h1&gt;
&lt;p&gt;关键概念: 文件系统，数据库系统
文件系统中，大量文件没有很好组织，缺乏对象之间关键，读取效率低，因此有了数据库。&lt;/p&gt;

&lt;p&gt;单台计算机无法满足数据存储和处理需求，需要集群化方案，如何高效读取分布式计算机文件，高效执行分布式数据库的SQL查询，就有了NOSQL。知名分布式文件系统HDFS，分布式非关系型(非结构化)数据库Hbase和MongoDB。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;分布式文件系统&lt;/h3&gt;
&lt;p&gt;2003年，Google发布论文GFS，启发Apache Nutch开发了HDFS。2004年，Google 又发布了论文《MapReduce: Simplified Data Processing on Large Clusters》，Doug Cutting等人实现计算框架MapReduce ，并与HDFS结合来更好的支持该框架。2006年项目从Butch搜索引擎中独立出来，成为了现在的Hadoop。&lt;/p&gt;

&lt;p&gt;GFS隐藏了底层的负载均衡，切片备份等细节，使复杂性透明化，并提供统一的文件系统接口。其成本低，容错高，高吞吐，适合超大数据集应用场景。&lt;/p&gt;

&lt;p&gt;HDFS原理: 
1、横向扩展，增加“数据节点”就能增加容量。
2、增加协调部门，“命名节点”维护元数据，负责文件系统的命名空间，控制外部访问，将数据块印射到数据节点。还会备份元数据从命名节点，它只与命名节点通信。
3、数据库在多个数据节点备份。&lt;/p&gt;

&lt;p&gt;弱点:
1.不适合实时数据访问。
2.无法高效存储小文件，太多小文件会降低命名节点检索效率，降低系统处理速度。
3.不支持多用户写入。
4.不支持文件任意位置修改，只能在文件末尾追加新数据。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;分布式数据库&lt;/h3&gt;
&lt;p&gt;Google发布论文《Bigtable: A Distributed Storage System for Structured Data》。&lt;/p&gt;

&lt;h3 id=&quot;hbase&quot;&gt;HBase&lt;/h3&gt;
&lt;p&gt;Hbase在HDFS基础上提供了&lt;strong&gt;Bigtable&lt;/strong&gt;的能力; 并且基于&lt;strong&gt;列&lt;/strong&gt;的模式进行存储。&lt;/p&gt;

&lt;p&gt;HBase的数据模型:
表格
行
列族
列限定符
单元
版本&lt;/p&gt;

&lt;p&gt;HBase体系结构:
HMaster
HRegion
HRegion服务器&lt;/p&gt;

&lt;p&gt;HBase的列存储设计非常方便扩展，可以修改列族定义、增加列族或列限定符，所以被成为“宽表”。&lt;/p&gt;

&lt;p&gt;宽表模式优点：
节省关系数据库连接操作和存储空间。
可将不同Schema模式的数据混合，即异构数据源的统一和集成。&lt;/p&gt;

&lt;h3 id=&quot;mongodb&quot;&gt;MongoDB&lt;/h3&gt;
&lt;p&gt;面向集合，数据分组存储在数据集，数据集被称为集合，每个集合在数据库有唯一标识，可以包含无数文档。&lt;/p&gt;

&lt;p&gt;与HBase区别：
1.数据直接存储在文件系统上，而非HDFS上。其也有大文件存储概念GridFS，由MongoDB自身实现。
2.数据模型以文档为单位，支持多种复杂结构。文档中字段或属性不限定特定类型。
3.单个文档不再切分和分布式存储。&lt;/p&gt;

&lt;h1 id=&quot;section-3&quot;&gt;非持久化存储&lt;/h1&gt;
&lt;p&gt;关键字：缓存和散列
散列：数据的散列值作为键，待写入的数据作为值，进行key-value配对存储。散列值由散列函数(算法)得出，好的算法尽量避免散列冲突(散列值不唯一)。&lt;/p&gt;

&lt;p&gt;提高缓存访问命中率：
淘汰算法:最少使用(LFU),最久未用(LRU)。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;缓存系统:&lt;/h3&gt;
&lt;p&gt;Memcached, Berkeley DB, Redis。
MongoDB也可以做缓存，Redis和Berkeley DB也支持持久化存储，没那么绝对。&lt;/p&gt;

&lt;p&gt;Memcached：
基于散列映射。
LRU。
客户端(任何语言)通过Memcached协议 来与守护进程通信(c语言)。
服务器端无切片和副本等分布式功能，服务器之间不通信，需要应用端实现。&lt;/p&gt;

&lt;p&gt;Berkeley DB(轻量级)：
嵌入式数据库系统。
架构简单，key-value。
支持ACID数据库事务处理，细粒度锁，XA接口，热备份，同步复制等。
核心不支持分布式，支持持久化。&lt;/p&gt;

&lt;p&gt;Redis(远程字典服务器):
1.超高性能，每秒数十万次。
2.支持字符串，散列表，列表，集合。
3.支持事务性，例如a转账给b，a扣钱，b加钱，如果b未加成功，a扣的钱返还。
4.可设定生命周期，为key-value设置生命周期(TTL)，例如验证码，限时特惠。
5.持久化，全量保存的RDB镜像(速度快)，增量保存的AOF日志(资源消耗少，丢失少)。
6.主从同步，从服务器利用发布/订阅机制从主服务器接收发布的记录。
7.哨兵，自动化监控和故障恢复。
8.适用读多写少，主服务器写，从服务器读，主服务器一旦出错，系统恢复麻烦。Redis3.0后提出了“集群”概念，包括预分片技术，对水平扩展更好的支持。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;分布式存储的三种类型：&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://www.infoq.com/cn/articles/virtual-forum-three-basic-issues-about-distributed-storage&quot;&gt;有关分布式存储的三个基本问题&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.testlab.com.cn/Index/article/id/1082.html&quot;&gt;文件系统vs对象存储——选型和趋势&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/21536660&quot;&gt;块存储、文件存储、对象存储这三者的本质差别是什么&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;分布式存储的应用场景相对于其存储接口，现在流行分为三种:&lt;/p&gt;

&lt;p&gt;对象存储: 也就是通常意义的键值存储，其接口就是简单的GET、PUT、DEL和其他扩展，如七牛、又拍、Swift、S3&lt;/p&gt;

&lt;p&gt;块存储: 这种接口通常以QEMU Driver或者Kernel Module的方式存在，这种接口需要实现Linux的Block Device的接口或者QEMU提供的Block Driver接口，如Sheepdog，AWS的EBS，青云的云硬盘和阿里云的盘古系统，还有Ceph的RBD（RBD是Ceph面向块存储的接口）&lt;/p&gt;

&lt;p&gt;文件存储: 通常意义是支持POSIX接口，它跟传统的文件系统如Ext4是一个类型的，但区别在于分布式存储提供了并行化的能力，如Ceph的CephFS(CephFS是Ceph面向文件存储的接口)，但是有时候又会把GFS，HDFS这种非POSIX接口的类文件存储接口归入此类。&lt;/p&gt;

</description>
        <pubDate>Wed, 26 Oct 2016 04:00:00 +0800</pubDate>
        <link>http://yhj167.github.io/2016/10/26/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/</link>
        <guid isPermaLink="true">http://yhj167.github.io/2016/10/26/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/</guid>
        
        <category>大数据与分布式系统</category>
        
        
      </item>
    
      <item>
        <title>[C++篇]如何正确学习C++ Primer这本书</title>
        <description>&lt;p&gt;首先，读一遍是不够的，所以第一遍要快读，然后再分而治之，深入研究，不断练习。&lt;/p&gt;

&lt;p&gt;以C++ Primer第五版为例，第一遍，除了个别章节要通读之外，其他都可以速读。个人建议通读章节如下：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Part1&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;3.2 string&lt;/p&gt;

  &lt;p&gt;3.3 vector&lt;/p&gt;

  &lt;p&gt;6.6 函数匹配&lt;/p&gt;

  &lt;p&gt;6.7 函数指针&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Part2&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;9 顺序容器&lt;/p&gt;

  &lt;p&gt;11 关联容器&lt;/p&gt;

  &lt;p&gt;10 泛型算法、函数式编程&lt;/p&gt;

  &lt;p&gt;12.1 智能指针&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Part3&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;13 初始化，复制，赋值，右值引用&lt;/p&gt;

  &lt;p&gt;14 运算符重载，14.9可以先跳过&lt;/p&gt;

  &lt;p&gt;16 泛型编程，函数模板、类模板&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;Part4&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;17.3正则表达式, 17.4随机数, 17.5 IO库&lt;/p&gt;

  &lt;p&gt;18.2 命名空间&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;最后建议从C到C++的使用者注意：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;尽量用容器代替原始数组&lt;/p&gt;

  &lt;p&gt;用static_cast代替括号强制转换&lt;/p&gt;

  &lt;p&gt;用string代替char*&lt;/p&gt;

  &lt;p&gt;用智能指针代替原始指针。当然I/O是个例外，printf()还是比cout好用；转换数字和字符串时sprintf()也比stringstream快&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;section&quot;&gt;参考链接&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/51560126&quot;&gt;如何高效学习C++?&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 19 Oct 2016 04:00:00 +0800</pubDate>
        <link>http://yhj167.github.io/2016/10/19/C++%E7%AF%87-%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E5%AD%A6%E4%B9%A0C++-Primer%E8%BF%99%E6%9C%AC%E4%B9%A6/</link>
        <guid isPermaLink="true">http://yhj167.github.io/2016/10/19/C++%E7%AF%87-%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E5%AD%A6%E4%B9%A0C++-Primer%E8%BF%99%E6%9C%AC%E4%B9%A6/</guid>
        
        <category>C++</category>
        
        <category>编程语言</category>
        
        
      </item>
    
      <item>
        <title>[大数据与分布式系统]文件系统原理分析</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;参考链接&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://www.sjhf.net/pdf/fat.pdf&quot;&gt;《FAT文件系统原理》&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;section-1&quot;&gt;为什么引入文件系统？&lt;/h4&gt;
&lt;p&gt;因为磁盘上面不仅要存放文件数据本身，还需要有对这些数据进行管理的数据，比如文件起始位置、大小、创建时间等。这些数据又叫做元数据（Metadata）。不同文件系统的元数据是不一样的。元数据会占用额外的磁盘空间，但总体比例不会很大，它对功能的实现和性能的提升有非常重要的作用。格式化文件系统，其实就是写入一些初始化的元数据的过程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/2886390-ab7d6fbee9984b87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/2886390-d0f0cf6910764c92.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图是一个完整的FAT32分区:
FAT1: 文件分配表，描述文件存储空间的簇链接关系(下一簇数据存储在哪个簇，因为同一个文件中数据的簇号是连续的)。
FAT2: FAT1的备份。
FDT: 文件目录表，描述了其他元数据信息(包括起始位置、大小、时间、权限等文件和目录属性)。&lt;/p&gt;

&lt;p&gt;这种链表式的存储方式效率不高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/2886390-b821fa98cf29a442.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;缺点:
1.簇为最小单元，磁盘利用率不够。
2.链表形式导致磁盘碎片，会降低访问速度。
3.掉电可能引起FAT表未刷新，簇映射乱掉。
4.需要FAT表和目录共同匹配才能识别文件。
5.容量有限，簇数增加会导致FAT表索引速度慢。&lt;/p&gt;

&lt;p&gt;Windows上用的FAT、NTFS，Linux下的ext4、XFS、btrfs都是常见的文件系统。FAT简单，用得也广，但功能、性能、对数据的保护度都有所欠缺。NTFS是Windows下推荐的文件系统。Linux中用ext4的人较多，这是大多数Linux发行版的默认文件系统。在服务器领域，用XFS的人较多，因为在部分环境下它能表现出较高的性能。&lt;/p&gt;

&lt;h4 id=&quot;section-2&quot;&gt;文件系统的发展&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;网络文件系统：如CIFS（Windows网上邻居所用的协议）和NFS，就是网络文件系统。它们和普通文件系统的概念有所差别，并不定义文件数据是如何在磁盘上面分布的，而是告诉网络中的客户端，文件数据应当如何传输，怎么通过网络访问远端的文件。所以，它实际上是搭建在普通文件系统之上的。提供网络文件服务的设备，需要有一个本地的文件系统（如ext4），然后在启动一个或多个网络文件系统，负责从普通文件系统中读取数据，向外传送。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;分布式文件系统或集群文件系统：如Hadoop中的HDFS。它们能把很多台电脑里的数据整合起来，对外表现出一个单一的存储节点，提供服务，实现性能扩展和高可靠性等高级特性。它们实际上也不会直接操作磁盘数据，而是叠加在普通文件系统之上的。用户对这类文件系统的IO请求，被它们处理之后，会转化为每一个节点上的普通IO，再调用本地的文件系统进行实际的数据读写。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;特殊文件系统：Linux下就有sysfs和procfs等特殊文件系统，用来管理系统设备，调用内核接口。它们和磁盘上的数据就没有任何直接的联系了，只是以文件接口的方式，提供了很多特殊功能给用户使用。因为在接口上面和普通文件读写类似，所以也被冠名为文件系统。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Mon, 17 Oct 2016 04:00:00 +0800</pubDate>
        <link>http://yhj167.github.io/2016/10/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/</link>
        <guid isPermaLink="true">http://yhj167.github.io/2016/10/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/</guid>
        
        <category>文件系统</category>
        
        <category>大数据与分布式系统</category>
        
        
      </item>
    
      <item>
        <title>[文件系统]块文件系统BUG引起的系统复位问题归零报告</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;故障现象&lt;/h3&gt;

&lt;p&gt;着陆时，MCU收集MFL数据并转发给VCM，由VCM存储到IDR记录卡。在MCU开始发送MFL数据9秒左右时，VCM复位。&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;section-1&quot;&gt;故障定位&lt;/h3&gt;

&lt;p&gt;测试发现，通过MCU端手动向双口长时间地周期（2个tick）写MFL数据，必然会导致VCM复位，有时候复位前会打印program和data access错误，有时候直接复位。&lt;/p&gt;

&lt;h4 id=&quot;section-2&quot;&gt;分析可能出现的几种复位方式：&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;应用监控的任务挂起，引起的手动开门狗复位；&lt;/li&gt;
  &lt;li&gt;应用异常导致CPU死机刚好无法喂狗，引起开门狗复位；&lt;/li&gt;
  &lt;li&gt;应用执行了非法指令、地址寻址错误、除数为0、负值长度等，导致CPU访问异常，引起CPU热复位。&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;测试1：在VCM监控任务中，将任务挂起手动停止喂狗功能注释掉。&lt;/p&gt;

    &lt;p&gt;结果：VCM还是会出现复位，排除第1种复位。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;测试2：在VCM应用中禁掉看门狗。&lt;/p&gt;

    &lt;p&gt;结果：VCM有时还是会复位，有时会死机。说明可能是CPU访问异常导致热复位，或异常时刚好无法喂狗导致看门狗复位。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们知道vxworks5.5操作系统是没有用户态的，用户没有自己的地址空间。所以应用访问异常的地址空间，很可能导致执行非法指令或寻址错误；甚至可能会导致CPU异常而reboot。&lt;/p&gt;

&lt;h4 id=&quot;section-3&quot;&gt;从数据流的过程分析可能引起复位的原因：&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;VCM和MCU的双口通信在数据量增大时是否可能访问数据越界。&lt;/li&gt;
  &lt;li&gt;VCM从双口取出数据存入本地缓存，写盘时从缓存中取数据，存取数据是否出错。&lt;/li&gt;
  &lt;li&gt;VCM写盘是否出错。&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;测试3：在VCM应用中，屏蔽从双口读取MFL数据，以相同的数据流量仿真MFL数据，放入本地的MFL缓存中，VCM按原来的方式从缓存中取数据写盘。&lt;/p&gt;

    &lt;p&gt;结果：VCM还是会出现复位，排除MCU和VCM的双口通信问题，同时也将问题定位到了VCM端。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;测试4：打印存放MFL的当前扇区的有效字节数oddment(即偏移量)、缓存中取出的数据长度getlen、块数blocknum。取数据和写盘的代码如下：&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;blocknum = nbforng/512;	//nbforng为本地缓存中数据字节数&lt;/p&gt;

      &lt;p&gt;if(blocknum == 0) blocknum = 2;&lt;/p&gt;

      &lt;p&gt;ldrs_rawFsGetWrtBuf(fd, WRITE_LEN_MAX, &amp;amp;oddment);	//获取块文件系统写数据存放缓冲区&lt;/p&gt;

      &lt;p&gt;getlen = getdatafromrngbuf(rngid, semid, buf, (512*blocknum)-oddment);	//从缓存中取数据&lt;/p&gt;

      &lt;p&gt;… …&lt;/p&gt;

      &lt;p&gt;idrs_rawFsWrite(fd, dataidx, buf, getlen);		//写盘&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;结果：发现打印的当前扇区有效字节数oddment出现大于512的情况，然而一个扇区最大为512字节。所以，&lt;strong&gt;当oddment&amp;gt;512，且512&amp;lt;nbforng&amp;lt;1024时，会出现blocknum等于1，(512*blocknum)-oddment)&amp;lt;0的情况，导致取数据的长度&amp;lt;0&lt;/strong&gt;。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;测试5：在串口中测试rngBufGet(MFL_ringid, buf, -1)，从MFL_ringid缓存中取-1长度的数据，会导致应用程序复位。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;section-4&quot;&gt;故障原因&lt;/h3&gt;

&lt;p&gt;VCM应用程序为了减少写盘次数，每次写盘都会凑512*blocknum字节的数据量，即凑完整的扇区来写盘。例如，缓存中数据量nbforng为1100字节，扇区偏移量oddment为124，则blocknum为2，算出实际写盘数据量为(512xblocknum)-oddment = 900字节，剩下的1100-900 = 200字节数据等下次写盘时再写。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一种异常情况，当环形缓存中数据量&amp;lt;512字节，即blocknum等于0时，取数据长度(512*blocknum)-oddment)为负值。应用对0值做了处理：&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;if(blocknum == 0) blocknum = 2;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;当环形缓存中数据量在512～1024字节范围，即blocknum等于1时，取数据长度(512*blocknum)-oddment)正常情况下为&amp;gt;=0，但实际oddment出现了&amp;gt;512的情况。因为当数据区通道数&amp;gt;1时，计算扇区偏移量oddment会加上14个字节的帧头，所以oddment的范围变为14～526了。&lt;/p&gt;

    &lt;p&gt;当oddment&amp;gt;512，且512&amp;lt;nbforng&amp;lt;1024，即blocknum等于1时，(512*blocknum)-oddment)&amp;lt;0，导致调用vxworks系统函数rngBufGet取数据时长度&amp;lt;0，CPU死机引起VCM应用程序复位。&lt;/p&gt;

    &lt;p&gt;那么，其他数据是否会引起同样的故障：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;LOG的数据区通道数为1且数据量小，oddment不会加14字节的帧头，oddment不会越界&amp;gt;512；&lt;/li&gt;
      &lt;li&gt;音视频正常数据量大，blocknum = nbforng/512，blocknum&amp;gt;2，而blocknum只有为1才会导致异常，所以基本不会引起异常；&lt;/li&gt;
      &lt;li&gt;电子战EW/武器BUS/飞参FPA/BM总线数据的正常数据量&amp;lt;512字节，blocknum为0，所以基本不会引起异常；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;测试6：同时，测试在vxworks6.8系统下，调用rngBufGet函数取负值长度的数据返回-1，但不会引起CPU死机。而10C使用的是vxworks6.8系统，并且没有采用这种凑512*blocknum字节数据量写盘的方式，所以10C不会出现这样的故障。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;section-5&quot;&gt;解决方案&lt;/h3&gt;

&lt;p&gt;块文件系统中判断逻辑，当数据区通道数&amp;gt;1时，写盘会增加14个字节，其中8个字节帧头，6个字节帧尾。而应用计算从本地缓存中可取数据量时，不包括这14字节（因为这是文件系统驱动中加的），所以为了留出14个字节，偏移量oddment计算时加上了14个字节：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;oddment = 14字节帧头帧尾 + 当前扇区实际偏移量oddment_actual;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;为了写扇区时凑完整的扇区，从缓存中取(blocknum*512)-oddment字节的数据，如下：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;//从缓存中取数据&lt;/p&gt;

  &lt;p&gt;getlen = getdatafromrngbuf(rngid, semid, buf, (blocknum*512)-oddment);&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;因为扇区偏移量oddment并非实际偏移量，其范围为14～526，可能导致(blocknum*512)-oddment为负值。所以，计算oddment时，得出的结果后面加一句：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;*oddment = *oddment%512;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;使得扇区偏移量范围在0～512字节之间。&lt;/p&gt;

&lt;p&gt;例如：缓存中数据量nbforng为600字节，实际偏移量oddment_actual为500字节时，计算oddment ＝ (500+14)%512 = 2，blocknum = nbforng/512 = 1，(blocknum*512)-oddment = 510。从缓存中取510字节，剩下600-510=90字节下次再写。实际写盘数据量为510+14=524字节，从扇区实际偏移量oddment_actual为500开始写，刚好写满下个扇区。&lt;/p&gt;
</description>
        <pubDate>Sat, 15 Oct 2016 04:00:00 +0800</pubDate>
        <link>http://yhj167.github.io/2016/10/15/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-%E5%9D%97%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9FBUG%E5%BC%95%E8%B5%B7%E7%9A%84%E7%B3%BB%E7%BB%9F%E5%A4%8D%E4%BD%8D%E9%97%AE%E9%A2%98%E5%BD%92%E9%9B%B6%E6%8A%A5%E5%91%8A/</link>
        <guid isPermaLink="true">http://yhj167.github.io/2016/10/15/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-%E5%9D%97%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9FBUG%E5%BC%95%E8%B5%B7%E7%9A%84%E7%B3%BB%E7%BB%9F%E5%A4%8D%E4%BD%8D%E9%97%AE%E9%A2%98%E5%BD%92%E9%9B%B6%E6%8A%A5%E5%91%8A/</guid>
        
        <category>文件系统</category>
        
        
      </item>
    
      <item>
        <title>[网络协议]基于UDP实现的可靠传输协议</title>
        <description>&lt;p&gt;UDP实现的可靠协议，基本都会对TCP的某一部分进行加强，另外一部分进行削弱。因为：
“实时性+可靠性+公平性” 三者不能同时保证，因此可以牺牲TCP的局部公平性来换取更好的实时性，或者更浪费点带宽，来实现更低的延迟。&lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;参考资料&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/20292749&quot;&gt;QQ 为什么采用 UDP 协议，而不采用 TCP 协议实现&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 23 Sep 2016 04:30:00 +0800</pubDate>
        <link>http://yhj167.github.io/2016/09/23/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%9F%BA%E4%BA%8EUDP%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE/</link>
        <guid isPermaLink="true">http://yhj167.github.io/2016/09/23/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%9F%BA%E4%BA%8EUDP%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE/</guid>
        
        <category>网络协议</category>
        
        
      </item>
    
      <item>
        <title>[网络协议]TCP粘包分析</title>
        <description>&lt;p&gt;这两天看csdn有一些关于socket粘包，socket缓冲区设置的问题，发现自己不是很清楚，所以查资料了解记录一下： 
一 .两个简单概念长连接与短连接：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;长连接
    Client方与Server方先建立通讯连接，连接建立后不断开， 然后再进行报文发送和接收。&lt;/li&gt;
  &lt;li&gt;短连接
    Client方与Server每进行一次报文收发交易时才进行通讯连接，交易完毕后立即断开连接。此种方式常用于一点对多点 
通讯，比如多个Client连接一个Server.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;二 .什么时候需要考虑粘包问题?
1:如果利用tcp每次发送数据，就与对方建立连接，然后双方发送完一段数据后，就关闭连接，这样就不会出现粘包问题（因为只有一种包结构,类似于http协议）。关闭连接主要要双方都发送close连接（参考tcp关闭协议）。如：A需要发送一段字符串给B，那么A与B建立连接，然后发送双方都默认好的协议字符如”hello give me sth abour yourself”，然后B收到报文后，就将缓冲区数据接收,然后关闭连接，这样粘包问题不用考虑到，因为大家都知道是发送一段字符。
2：如果发送数据无结构，如文件传输，这样发送方只管发送，接收方只管接收存储就ok，也不用考虑粘包
3：如果双方建立连接，需要在连接后一段时间内发送不同结构数据，如连接后，有好几种结构：
 1)”hello give me sth abour yourself” 
 2)”Don’t give me sth abour yourself” 
   那这样的话，如果发送方连续发送这个两个包出去，接收方一次接收可能会是”hello give me sth abour yourselfDon’t give me sth abour yourself” 这样接收方就傻了，到底是要干嘛？不知道，因为协议没有规定这么诡异的字符串，所以要处理把它分包，怎么分也需要双方组织一个比较好的包结构，所以一般可能会在头加一个数据长度之类的包，以确保接收。&lt;/p&gt;

&lt;p&gt;三 .粘包出现原因：在流传输中出现，UDP不会出现粘包，因为它有消息边界(参考Windows 网络编程)
1 发送端需要等缓冲区满才发送出去，造成粘包
2 接收方不及时接收缓冲区的包，造成多个包接收
解决办法：
为了避免粘包现象，可采取以下几种措施。一是对于发送方引起的粘包现象，用户可通过编程设置来避免，TCP提供了强制数据立即传送的操作指令push，TCP软件收到该操作指令后，就立即将本段数据发送出去，而不必等待发送缓冲区满；二是对于接收方引起的粘包，则可通过优化程序设计、精简接收进程工作量、提高接收进程优先级等措施，使其及时接收数据，从而尽量避免出现粘包现象；三是由接收方控制，将一包数据按结构字段，人为控制分多次接收，然后合并，通过这种手段来避免粘包。
以上提到的三种措施，都有其不足之处。第一种编程设置方法虽然可以避免发送方引起的粘包，但它关闭了优化算法，降低了网络发送效率，影响应用程序的性能，一般不建议使用。第二种方法只能减少出现粘包的可能性，但并不能完全避免粘包，当发送频率较高时，或由于网络突发可能使某个时间段数据包到达接收方较快，接收方还是有可能来不及接收，从而导致粘包。第三种方法虽然避免了粘包，但应用程序的效率较低，对实时应用的场合不适合。
载自：http://blog.csdn.net/binghuazh/archive/2009/05/28/4222516.aspx&lt;/p&gt;

&lt;h1 id=&quot;section&quot;&gt;网络通讯的封包和拆包&lt;/h1&gt;
&lt;p&gt;对于基于TCP开发的通讯程序,有个很重要的问题需要解决,就是封包和拆包.
一.为什么基于TCP的通讯程序需要进行封包和拆包.
TCP是个”流”协议,所谓流,就是没有界限的一串数据.大家可以想想河里的流水,是连成一片的,其间是没有分界线的.但一般通讯程序开发是需要定义一个个相互独立的数据包的,比如用于登陆的数据包,用于注销的数据包.由于TCP”流”的特性以及网络状况,在进行数据传输时会出现以下几种情况.
假设我们连续调用两次send分别发送两段数据data1和data2,在接收端有以下几种接收情况(当然不止这几种情况,这里只列出了有代表性的情况).
A.先接收到data1,然后接收到data2.
B.先接收到data1的部分数据,然后接收到data1余下的部分以及data2的全部.
C.先接收到了data1的全部数据和data2的部分数据,然后接收到了data2的余下的数据.
D.一次性接收到了data1和data2的全部数据.
对于A这种情况正是我们需要的,不再做讨论.对于B,C,D的情况就是大家经常说的”粘包”,就需要我们把接收到的数据进行拆包,拆成一个个独立的数据包.为了拆包就必须在发送端进行封包.
另:对于UDP来说就不存在拆包的问题,因为UDP是个”数据包”协议,也就是两段数据间是有界限的,在接收端要么接收不到数据要么就是接收一个完整的一段数据,不会少接收也不会多接收.
二.为什么会出现B.C.D的情况.
“粘包”可发生在发送端也可发生在接收端.
1.由Nagle算法造成的发送端的粘包:Nagle算法是一种改善网络传输效率的算法.简单的说,当我们提交一段数据给TCP发送时,TCP并不立刻发送此段数据,而是等待一小段时间,看看在等待期间是否还有要发送的数据,若有则会一次把这两段数据发送出去.这是对Nagle算法一个简单的解释,详细的请看相关书籍.象C和D的情况就有可能是Nagle算法造成的.
2.接收端接收不及时造成的接收端粘包:TCP会把接收到的数据存在自己的缓冲区中,然后通知应用层取数据.当应用层由于某些原因不能及时的把TCP的数据取出来,就会造成TCP缓冲区中存放了几段数据.
三.怎样封包和拆包.
   最初遇到”粘包”的问题时,我是通过在两次send之间调用sleep来休眠一小段时间来解决.这个解决方法的缺点是显而易见的,使传输效率大大降低,而且也并不可靠.后来就是通过应答的方式来解决,尽管在大多数时候是可行的,但是不能解决象B的那种情况,而且采用应答方式增加了通讯量,加重了网络负荷. 再后来就是对数据包进行封包和拆包的操作.
    封包:
封包就是给一段数据加上包头,这样一来数据包就分为包头和包体两部分内容了(以后讲过滤非法包时封包会加入”包尾”内容).包头其实上是个大小固定的结构体,其中有个结构体成员变量表示包体的长度,这是个很重要的变量,其他的结构体成员可根据需要自己定义.根据包头长度固定以及包头中含有包体长度的变量就能正确的拆分出一个完整的数据包.
    对于拆包目前我最常用的是以下两种方式.
    1.动态缓冲区暂存方式.之所以说缓冲区是动态的是因为当需要缓冲的数据长度超出缓冲区的长度时会增大缓冲区长度.
    大概过程描述如下:
    A,为每一个连接动态分配一个缓冲区,同时把此缓冲区和SOCKET关联,常用的是通过结构体关联.
    B,当接收到数据时首先把此段数据存放在缓冲区中.
    C,判断缓存区中的数据长度是否够一个包头的长度,如不够,则不进行拆包操作.
    D,根据包头数据解析出里面代表包体长度的变量.
    E,判断缓存区中除包头外的数据长度是否够一个包体的长度,如不够,则不进行拆包操作.
    F,取出整个数据包.这里的”取”的意思是不光从缓冲区中拷贝出数据包,而且要把此数据包从缓存区中删除掉.删除的办法就是把此包后面的数据移动到缓冲区的起始地址.
这种方法有两个缺点.1.为每个连接动态分配一个缓冲区增大了内存的使用.2.有三个地方需要拷贝数据,一个地方是把数据存放在缓冲区,一个地方是把完整的数据包从缓冲区取出来,一个地方是把数据包从缓冲区中删除.第二种拆包的方法会解决和完善这些缺点.
前面提到过这种方法的缺点.下面给出一个改进办法, 即采用环形缓冲.但是这种改进方法还是不能解决第一个缺点以及第一个数据拷贝,只能解决第三个地方的数据拷贝(这个地方是拷贝数据最多的地方).第2种拆包方式会解决这两个问题.
环形缓冲实现方案是定义两个指针,分别指向有效数据的头和尾.在存放数据和删除数据时只是进行头尾指针的移动.
2.利用底层的缓冲区来进行拆包
由于TCP也维护了一个缓冲区,所以我们完全可以利用TCP的缓冲区来缓存我们的数据,这样一来就不需要为每一个连接分配一个缓冲区了.另一方面我们知道recv或者wsarecv都有一个参数,用来表示我们要接收多长长度的数据.利用这两个条件我们就可以对第一种方法进行优化.
     对于阻塞SOCKET来说,我们可以利用一个循环来接收包头长度的数据,然后解析出代表包体长度的那个变量,再用一个循环来接收包体长度的数据.
相关代码如下:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
char PackageHead[1024];
char PackageContext[1024*20];
int len;
PACKAGE_HEAD *pPackageHead;
while( m_bClose == false )
{
memset(PackageHead,0,sizeof(PACKAGE_HEAD));
len = m_TcpSock.ReceiveSize((char*)PackageHead,sizeof(PACKAGE_HEAD));
if( len == SOCKET_ERROR )
{
    break;
}
if(len == 0)
{
    break;
}
pPackageHead = (PACKAGE_HEAD *)PackageHead;
memset(PackageContext,0,sizeof(PackageContext));
if(pPackageHead-&amp;gt;nDataLen&amp;gt;0)
{
len = m_TcpSock.ReceiveSize((char*)PackageContext,pPackageHead-&amp;gt;nDataLen);
}
        }
m_TcpSock是一个封装了SOCKET的类的变量,其中的ReceiveSize用于接收一定长度的数据,直到接收了一定长度的数据或者网络出错才返回.

int winSocket::ReceiveSize( char* strData, int iLen )
{
if( strData == NULL )
return ERR_BADPARAM;
char *p = strData;
int len = iLen;
int ret = 0;
int returnlen = 0;
while( len &amp;gt; 0)
{
ret = recv( m_hSocket, p+(iLen-len), iLen-returnlen, 0 );
if ( ret == SOCKET_ERROR || ret == 0 )
{
return ret;
}
len -= ret;
returnlen += ret;
}
return returnlen;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于非阻塞的SOCKET,比如完成端口,我们可以提交接收包头长度的数据的请求,当 GetQueuedCompletionStatus返回时,我们判断接收的数据长度是否等于包头长度,若等于,则提交接收包体长度的数据的请求,若不等于则提交接收剩余数据的请求.当接收包体时,采用类似的方法.
载自： http://blog.csdn.net/fjcailei/archive/2009/06/17/4276463.aspx&lt;/p&gt;

&lt;h1 id=&quot;section-1&quot;&gt;这个问题产生于编程中遇到的几个问题：&lt;/h1&gt;
&lt;p&gt;几个问题：http://www.qqgb.com/Program/VC/VCJQ/Program_200509.html
1、使用TCP的Socket发送数据的时候，会出现发送出错，WSAEWOULDBLOCK，在TCP中不是会保证发送的数据能够安全的到达接收端的吗？也有窗口机制去防止发送速度过快，为什么还会出错呢？&lt;/p&gt;

&lt;p&gt;2、TCP协议，在使用Socket发送数据的时候，每次发送一个包，接收端是完整的接受到一个包还是怎么样？如果是每发一个包，就接受一个包，为什么还会出现粘包问题，具体是怎么运行的？&lt;/p&gt;

&lt;p&gt;3、关于Send，是不是只有在非阻塞状态下才会出现实际发送的比指定发送的小？在阻塞状态下会不会出现实际发送的比指定发送的小，就是说只能出现要么全发送，要么不发送？在非阻塞状态下，如果之发送了一些数据，要怎么处理，调用了Send函数后，发现返回值比指定的要小，具体要怎么做？&lt;/p&gt;

&lt;p&gt;4、最后一个问题，就是TCP/IP协议和Socket是什么关系？是指具体的实现上，Socket是TCP/IP的实现？那么为什么会出现使用TCP协议的Socket会发送出错（又回到第一个问题了，汗一个）&lt;/p&gt;

&lt;p&gt;实在是有点晕了，如果我的问题有不清楚的地方，或者分数有问题，欢迎指出，谢谢
这个问题第1个回答：
1 应该是你的缓冲区不够大, 
2 tcp是流,没有界限.也就所所谓的包. 
3 阻塞也会出现这种现象,出现后继续发送没发送出去的. 
4 tcp是协议,socket是一种接口,没必然联系.错误取决于你使用接口的问题,跟tcp没关系.
这个问题第2个回答：
1 应该是你的缓冲区不够大, 
2 tcp是流,没有界限.也就无所谓包. 
3 阻塞也会出现这种现象,出现后继续发送没发送出去的. 
4 tcp是协议,socket是一种接口,没必然联系.错误取决于你使用接口的问题,跟tcp没关系.
这个问题第3个回答：
1、应该不是缓冲区大小问题，我试过设置缓冲区大小，不过这里有个问题，就是就算我把缓冲区设置成几G，也返回成功，不过实际上怎么可能设置那么大、、、&lt;/p&gt;

&lt;p&gt;3、出现没发送完的时候要手动发送吧，有没有具体的代码实现？&lt;/p&gt;

&lt;p&gt;4、当选择TCP的Socket发送数据的时候，TCP中的窗口机制不是能防止发送速度过快的吗？为什么Socket在出现了WSAEWOULDBLOCK后没有处理？
这个问题第4个回答：
1.在使用非阻塞模式的情况下，如果系统发送缓冲区已满，并示及时发送到对端，就会产生该错误，继续重试即可。 
3.如果没有发完就继续发送后续部分即可。
这个问题第5个回答：
1、使用非阻塞模式时，如果当前操作不能立即完成则会返回失败，错误码是WSAEWOULDBLOCK，这是正常的，程序可以先执行其它任务，过一段时间后再重试该操作。 
2、发送与接收不是一一对应的，TCP会把各次发送的数据重新组合，可能合并也可能拆分，但发送次序是不变的。 
3、在各种情况下都要根据send的返回值来确定发送了多少数据，没有发送完就再接着发。 
4、socket是Windows提供网络编程接口，TCP/IP是网络传输协议，使用socket是可以使用多种协议，其中包括TCP/IP。
这个问题第6个回答：
发送的过程是：发送到缓冲区和从缓冲区发送到网络上
WSAEWOULDBLOCK和粘包都是出现在发送到缓冲区这个过程的。&lt;/p&gt;
</description>
        <pubDate>Wed, 21 Sep 2016 05:00:00 +0800</pubDate>
        <link>http://yhj167.github.io/2016/09/21/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-TCP%E7%B2%98%E5%8C%85%E6%8B%BC%E5%8C%85%E5%88%86%E6%9E%90/</link>
        <guid isPermaLink="true">http://yhj167.github.io/2016/09/21/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-TCP%E7%B2%98%E5%8C%85%E6%8B%BC%E5%8C%85%E5%88%86%E6%9E%90/</guid>
        
        <category>网络协议</category>
        
        
      </item>
    
      <item>
        <title>[常用命令]Git命令(持续更新)</title>
        <description>&lt;h3 id=&quot;git&quot;&gt;取得Git仓库&lt;/h3&gt;

&lt;p&gt;初始化一个版本仓库&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git init&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Clone远程版本库&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git clone https://github.com/yhj167/yhj167.github.io.git&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;添加远程版本库origin，语法为 git remote add [shortname] [url]&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git remote add origin https://github.com/yhj167/yhj167.github.io.git&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;查看远程仓库&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git remote -v&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;section&quot;&gt;提交你的修改&lt;/h3&gt;

&lt;p&gt;添加当前修改的文件到暂存区&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git add .&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;添加所有修改的文件到暂存区&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git add -A&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;提交你的修改&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git commit –m “你的注释”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;推送你的更新到远程服务器,语法为 git push [远程名] [本地分支]:[远程分支]&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git push origin master&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;查看文件状态&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git status&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;从当前跟踪列表移除文件，并完全删除&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git rm readme.txt&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;仅在暂存区删除，保留文件在当前目录，不再跟踪&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git rm –cached readme.txt&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;重命名文件&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git mv reademe.txt readme&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;查看提交的历史记录&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git log&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;取消对文件的修改&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout –- readme.txt&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;section-1&quot;&gt;基本的分支管理&lt;/h3&gt;

&lt;p&gt;拉去远程仓库的数据，语法为 git fetch [remote-name]&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git fetch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;fetch 会拉取最新的远程仓库数据，但不会自动到当前目录下，要自动合并&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git pull&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;查看远程仓库的信息&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git remote show origin&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;push所有分支&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git push&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;将本地主分支推到远程主分支&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git push origin master&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;将本地主分支推到远程(如无远程主分支则创建，客户端首次提交)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git push -u origin master&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;git-1&quot;&gt;Git回退到某个历史版本&lt;/h3&gt;

&lt;p&gt;1.使用Git log命令查看所有的历史版本，获取某个历史版本的id，假设查到历史版本的id。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git reset –hard id&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;2.把修改推到远程服务器&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git push -f -u origin master&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;section-2&quot;&gt;例子&lt;/h3&gt;

&lt;p&gt;首次创建git库&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;echo &quot;# hyaojia.github.io&quot; &amp;gt;&amp;gt; README.md
git init
git add README.md
git commit -m &quot;first commit&quot;
git remote add origin https://github.com/hyaojia/hyaojia.github.io.git
git push -u origin master
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;如果不想每次更新博客后都要提交一遍才能看效果，可以启动本地jekyll服务:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;$ jekyll serve –watch
然后访问http://localhost:4000，按CTRL+C退出。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://xbc.me/git-commands/&quot;&gt;参考资料&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 12 Sep 2016 04:10:00 +0800</pubDate>
        <link>http://yhj167.github.io/2016/09/12/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4-Git%E5%91%BD%E4%BB%A4(%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0)/</link>
        <guid isPermaLink="true">http://yhj167.github.io/2016/09/12/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4-Git%E5%91%BD%E4%BB%A4(%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0)/</guid>
        
        <category>常用命令</category>
        
        
      </item>
    
  </channel>
</rss>
